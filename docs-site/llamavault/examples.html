<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Examples - LlamaVault Documentation</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            padding-top: 56px;
        }
        .hero {
            background-color: #f8f9fa;
            padding: 2rem 0;
            text-align: center;
        }
        .content {
            padding: 3rem 0;
        }
        .sidebar {
            background-color: #f8f9fa;
            padding: 1rem;
            border-radius: 0.25rem;
        }
        .footer {
            background-color: #f8f9fa;
            padding: 2rem 0;
            margin-top: 3rem;
        }
        pre {
            background-color: #f8f9fa;
            padding: 1rem;
            border-radius: 0.25rem;
        }
        code {
            color: #d63384;
        }
    </style>
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
            <a class="navbar-brand" href="../index.html">LlamaSearch.ai</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../llamapackages/index.html">LlamaPackages</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link active" href="index.html">LlamaVault</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/llamasearchai">GitHub</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="hero">
        <div class="container">
            <h1>LlamaVault Examples</h1>
            <p class="lead">Practical examples for using LlamaVault in real-world scenarios</p>
        </div>
    </div>

    <div class="container content">
        <div class="row">
            <div class="col-md-3">
                <div class="sidebar sticky-top" style="top: 80px;">
                    <h5>Documentation</h5>
                    <ul class="list-unstyled">
                        <li><a href="getting_started.html">Getting Started</a></li>
                        <li><a href="installation.html">Installation</a></li>
                        <li><a href="basic_usage.html">Basic Usage</a></li>
                        <li><a href="api_reference.html">API Reference</a></li>
                        <li><a href="advanced_usage.html">Advanced Usage</a></li>
                        <li><a href="security.html">Security Guide</a></li>
                        <li><a href="examples.html" class="fw-bold">Examples</a></li>
                        <li><a href="integrations.html">Integrations</a></li>
                    </ul>
                    <h5 class="mt-4">Resources</h5>
                    <ul class="list-unstyled">
                        <li><a href="https://github.com/llamasearchai/llamavault">GitHub Repository</a></li>
                        <li><a href="../docs/contributing.html">Contributing Guide</a></li>
                        <li><a href="../docs/changelog.html">Changelog</a></li>
                    </ul>
                </div>
            </div>
            <div class="col-md-9">
                <h2>LlamaVault Examples</h2>
                <p>This page provides practical examples of using LlamaVault in various scenarios. Each example includes sample code that you can adapt for your own projects.</p>
                
                <div class="card mb-4">
                    <div class="card-header">
                        <h3 id="basic-usage">Basic Usage Example</h3>
                    </div>
                    <div class="card-body">
                        <p>This example demonstrates the basic functionality of LlamaVault, including creating a vault, adding credentials, and retrieving them.</p>
                        <pre><code>import llamavault

# Initialize a vault
vault = llamavault.Vault()

# Add credentials
vault.add("api_key", "my-secret-api-key")
vault.add("database", {
    "host": "localhost",
    "port": 5432,
    "username": "admin",
    "password": "secret"
})

# Retrieve credentials
api_key = vault.get("api_key")
db_info = vault.get("database")

# Use credentials
print(f"API Key: {api_key}")
print(f"Database Connection: {db_info['username']}@{db_info['host']}:{db_info['port']}")</code></pre>
                    </div>
                </div>

                <div class="card mb-4">
                    <div class="card-header">
                        <h3 id="ai-integration">AI Integration Example</h3>
                    </div>
                    <div class="card-body">
                        <p>This example shows how to use LlamaVault to manage API keys for different AI services, making it easy to switch between providers or environments.</p>
                        <pre><code>import llamavault
import openai
import anthropic

class AIManager:
    def __init__(self):
        self.vault = llamavault.Vault()
        
    def get_openai_client(self):
        """Get an authenticated OpenAI client."""
        api_key = self.vault.get("openai_api_key")
        client = openai.OpenAI(api_key=api_key)
        return client
    
    def get_anthropic_client(self):
        """Get an authenticated Anthropic client."""
        api_key = self.vault.get("anthropic_api_key")
        client = anthropic.Anthropic(api_key=api_key)
        return client
    
    def generate_text(self, provider, prompt):
        """Generate text using the specified AI provider."""
        if provider == "openai":
            client = self.get_openai_client()
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
        
        elif provider == "anthropic":
            client = self.get_anthropic_client()
            response = client.completions.create(
                model="claude-2",
                prompt=prompt,
                max_tokens_to_sample=1000
            )
            return response.completion
        
        else:
            raise ValueError(f"Unsupported provider: {provider}")

# Usage
ai_manager = AIManager()
response = ai_manager.generate_text("openai", "Explain quantum computing in simple terms")</code></pre>
                    </div>
                </div>

                <div class="card mb-4">
                    <div class="card-header">
                        <h3 id="cli-example">Command-Line Tool Example</h3>
                    </div>
                    <div class="card-body">
                        <p>This example demonstrates how to create a command-line tool that uses LlamaVault to securely store and retrieve credentials.</p>
                        <pre><code>#!/usr/bin/env python3
import argparse
import llamavault
import sys

def main():
    parser = argparse.ArgumentParser(description="CLI tool with secure credential management")
    subparsers = parser.add_subparsers(dest="command", help="Command to run")
    
    # Config command
    config_parser = subparsers.add_parser("config", help="Configure credentials")
    config_parser.add_argument("--api-key", help="Set API key")
    config_parser.add_argument("--endpoint", help="Set API endpoint")
    
    # Run command
    run_parser = subparsers.add_parser("run", help="Run a task using stored credentials")
    run_parser.add_argument("task", help="Task to run")
    
    args = parser.parse_args()
    
    # Initialize vault
    vault = llamavault.Vault()
    
    if args.command == "config":
        if args.api_key:
            vault.add("api_key", args.api_key)
            print("API key stored successfully")
        
        if args.endpoint:
            vault.add("endpoint", args.endpoint)
            print("Endpoint stored successfully")
            
    elif args.command == "run":
        # Retrieve credentials
        try:
            api_key = vault.get("api_key")
            endpoint = vault.get("endpoint")
        except KeyError as e:
            print(f"Missing credential: {e}. Please run 'config' command first.")
            sys.exit(1)
            
        print(f"Running task '{args.task}' with endpoint {endpoint}")
        # Actual implementation would use the API key to authenticate the request
        
    else:
        parser.print_help()

if __name__ == "__main__":
    main()</code></pre>
                    </div>
                </div>

                <div class="card mb-4">
                    <div class="card-header">
                        <h3 id="ci-cd-integration">CI/CD Integration Example</h3>
                    </div>
                    <div class="card-body">
                        <p>This example shows how to use LlamaVault in a CI/CD pipeline to securely provide credentials to your build and deployment processes. This example uses GitHub Actions.</p>
                        <pre><code>import llamavault
import os
import subprocess
import json

class GitHubActionsIntegration:
    def __init__(self):
        self.vault = llamavault.Vault()
        
    def set_secret(self, repo, secret_name, secret_value):
        """Set a GitHub repository secret using the GitHub CLI."""
        # Check if gh CLI is installed
        try:
            subprocess.run(["gh", "--version"], check=True, capture_output=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            raise RuntimeError("GitHub CLI not installed or not working correctly")
        
        # Set the secret
        cmd = ["gh", "secret", "set", secret_name, "--body", secret_value, "--repo", repo]
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"Secret {secret_name} set successfully for {repo}")
    
    def export_secrets_to_github(self, repo, credential_keys):
        """Export multiple credentials to GitHub secrets."""
        for key in credential_keys:
            value = self.vault.get(key)
            if isinstance(value, dict):
                # For dictionary values, JSON-encode them
                value = json.dumps(value)
            self.set_secret(repo, key.upper(), value)
    
    def export_env_vars_to_workflow_file(self, workflow_file, credential_keys):
        """Update a GitHub Actions workflow file to use secrets as environment variables."""
        with open(workflow_file, 'r') as f:
            content = f.read()
        
        # Find the env section or create one
        if "env:" not in content:
            # Different strategies depending on the file structure
            # This is a simplified example - real implementation would be more robust
            updated_content = content.replace(
                "jobs:", 
                "env:\n" + "\n".join([f"  {key.upper()}: ${{{{ secrets.{key.upper()} }}}}" for key in credential_keys]) + "\n\njobs:"
            )
        else:
            # If env already exists, append to it
            # This is a simplified approach - real implementation would be more robust
            env_section = "env:\n" + "\n".join([f"  {key.upper()}: ${{{{ secrets.{key.upper()} }}}}" for key in credential_keys])
            updated_content = content.replace("env:", env_section)
        
        with open(workflow_file, 'w') as f:
            f.write(updated_content)
        
        print(f"Updated workflow file {workflow_file} with environment variables")

# Usage example
if __name__ == "__main__":
    integration = GitHubActionsIntegration()
    
    # Export credentials to GitHub secrets
    integration.export_secrets_to_github(
        "llamasearchai/my-project",
        ["api_key", "database_credentials", "aws_access_key"]
    )
    
    # Update a workflow file to use the secrets
    integration.export_env_vars_to_workflow_file(
        ".github/workflows/deploy.yml",
        ["api_key", "database_credentials", "aws_access_key"]
    )</code></pre>
                    </div>
                </div>

                <div class="card mb-4">
                    <div class="card-header">
                        <h3 id="docker-integration">Docker Integration Example</h3>
                    </div>
                    <div class="card-body">
                        <p>This example demonstrates how to use LlamaVault with Docker, passing credentials securely to containers.</p>
                        <pre><code>import llamavault
import subprocess
import os
import tempfile

class DockerManager:
    def __init__(self):
        self.vault = llamavault.Vault()
    
    def create_env_file(self, credential_keys):
        """Create a temporary .env file with credentials."""
        env_content = ""
        for key in credential_keys:
            value = self.vault.get(key)
            if isinstance(value, dict):
                # Handle dictionary values (flatten with prefix)
                for k, v in value.items():
                    env_content += f"{key.upper()}_{k.upper()}={v}\n"
            else:
                env_content += f"{key.upper()}={value}\n"
        
        # Write to temporary file
        fd, path = tempfile.mkstemp(suffix=".env")
        with os.fdopen(fd, 'w') as f:
            f.write(env_content)
        
        return path
    
    def run_container(self, image, credential_keys, command=None):
        """Run a Docker container with credentials passed as environment variables."""
        env_file = self.create_env_file(credential_keys)
        
        try:
            cmd = ["docker", "run", "--env-file", env_file]
            if command:
                cmd.extend(["--rm", image, command])
            else:
                cmd.extend(["--rm", image])
            
            print(f"Running container: {image}")
            subprocess.run(cmd, check=True)
        finally:
            # Clean up the temporary env file
            os.unlink(env_file)
    
    def run_docker_compose(self, compose_file, credential_keys):
        """Run docker-compose with credentials passed as environment variables."""
        env_file = self.create_env_file(credential_keys)
        
        try:
            cmd = ["docker-compose", "-f", compose_file, "--env-file", env_file, "up", "-d"]
            
            print(f"Running docker-compose with file: {compose_file}")
            subprocess.run(cmd, check=True)
        finally:
            # Clean up the temporary env file
            os.unlink(env_file)

# Usage example
if __name__ == "__main__":
    docker_manager = DockerManager()
    
    # Run a single container
    docker_manager.run_container(
        "my-api-service",
        ["api_key", "database_credentials"]
    )
    
    # Run a docker-compose setup
    docker_manager.run_docker_compose(
        "docker-compose.yml",
        ["api_key", "database_credentials", "aws_credentials"]
    )</code></pre>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <footer class="footer">
        <div class="container">
            <div class="row">
                <div class="col-md-6">
                    <h3>LlamaSearch.ai</h3>
                    <p>Building powerful tools for AI developers</p>
                </div>
                <div class="col-md-6 text-md-end">
                    <a href="https://github.com/llamasearchai" class="btn btn-outline-dark">GitHub</a>
                </div>
            </div>
            <hr>
            <p class="text-center">&copy; 2023 LlamaSearch.ai. All rights reserved.</p>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html> 